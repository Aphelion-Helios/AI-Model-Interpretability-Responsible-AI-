# AI-Model-Interpretability-Responsible-AI-
AI Model Explainability and Transparency

Have you been rejected from a job by an ATS? Chances are, it was a poorly trained one. Do you now someone who was denied a loan without any reason? How do you ensure you algorithm doesn't discriminate? You hold it accountable. This notebook lists a few Pythonian ways to do so, using libraries that explain the way predictions are made.
Please upvote this if you find it useful

# Jupyter Notebook Viewer Link for Visualiazations and Transformer Pipelines
- https://nbviewer.org/github/Aphelion-Helios/AI-Model-Interpretability-Responsible-AI-/blob/main/ai_model_explainability_and_transparency.ipynb
